{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Airport file from airports_test.txt\n",
      "There were 2 Airports with IATA code\n",
      "Reading Routes file from routes_test.txt\n",
      "Sink nodes: 0 for origin and 0 destination\n",
      "Converged after 1 iterations and 0.0 s\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from heapq import heappush\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, origin=None, destination=None):\n",
    "        self.origin = origin\n",
    "        self.weight = 1\n",
    "        self.destination = destination\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"edge: {self.origin} {self.weight} {self.destination}\"\n",
    "\n",
    "\n",
    "class Airport:\n",
    "    def __init__(self, iden=None, name=None):\n",
    "        self.code = iden\n",
    "        self.name = name\n",
    "        self.routes = []\n",
    "        self.routeHash = dict()\n",
    "        self.outweight = 0\n",
    "        self.pageIndex = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.code}\\t{self.outweight}\\t{self.name}\"\n",
    "\n",
    "    def add_destination(self, destination_airport, weight=1):\n",
    "        if destination_airport.code in self.routeHash:\n",
    "            self.routeHash[destination_airport.code] += weight\n",
    "        else:\n",
    "            self.routes.append(destination_airport)\n",
    "            self.routeHash[destination_airport.code] = weight\n",
    "\n",
    "        self.outweight += weight\n",
    "\n",
    "\n",
    "edgesHash = dict()\n",
    "airportList = []\n",
    "airportHash = dict()\n",
    "\n",
    "def readAirports(fd):\n",
    "    print(\"Reading Airport file from {0}\".format(fd))\n",
    "    airportsTxt = open(fd, \"r\", encoding=\"utf-8\")\n",
    "    cont = 0\n",
    "    for line in airportsTxt.readlines():\n",
    "        a = Airport()\n",
    "        try:\n",
    "            temp = line.split(',')\n",
    "            if len(temp[4]) != 5:\n",
    "                raise Exception('not an IATA code')\n",
    "            \n",
    "            code = temp[4][1:-1]\n",
    "            # check for valid codes\n",
    "            if len(code) == 3 and code.isalpha():\n",
    "                a.code = code\n",
    "                a.name = temp[1][1:-1] + \", \" + temp[3][1:-1]\n",
    "                cont += 1\n",
    "                airportList.append(a)\n",
    "                airportHash[a.code] = a\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    airportsTxt.close()\n",
    "    print(f\"There were {cont} Airports with IATA code\")\n",
    "\n",
    "def readRoutes(fd):\n",
    "    print(f\"Reading Routes file from {fd}\")\n",
    "    routesTxt = open(fd, \"r\", encoding=\"utf-8\")\n",
    "    missing_IATA_code = {\"origin\": [], \"destination\": []}\n",
    "    for line in routesTxt.readlines():\n",
    "        try:\n",
    "            temp = line.split(',')\n",
    "            origin = temp[2]\n",
    "            destination = temp[4]\n",
    "\n",
    "            if len(origin) == 3 and origin.isalpha() and len(destination) == 3 and destination.isalpha():\n",
    "                if origin not in airportHash:\n",
    "                    missing_IATA_code[\"origin\"].append(destination)\n",
    "                    new_airport = Airport(origin, \"NaN\")\n",
    "                    airportHash[origin] = new_airport\n",
    "                    airportList.append(new_airport)\n",
    "                elif destination not in airportHash:\n",
    "                    missing_IATA_code[\"destination\"].append(origin)\n",
    "                    new_airport = Airport(destination, \"NaN\")\n",
    "                    airportHash[destination] = new_airport\n",
    "                    airportList.append(new_airport)\n",
    "\n",
    "                airportHash[origin].add_destination(airportHash[destination])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(f\"Sink nodes: {len(missing_IATA_code['origin'])} for origin and {len(missing_IATA_code['destination'])} destination\")\n",
    "\n",
    "\n",
    "def computePageRanks(airports_list, airport_hash, epsilon=1e-10, L=0.8, max_iter=5000):\n",
    "    time1 = time.time()\n",
    "    n = len(airports_list)\n",
    "    \n",
    "    # Initialize PageRank values (uniform distribution initially)\n",
    "    P = np.ones(n) / n\n",
    "    teleport = (1 - L) / n\n",
    "\n",
    "    # Create an empty heap to store (page rank, airport code) pairs\n",
    "    heap = []\n",
    "\n",
    "    # Iterate for a maximum of `max_iter` iterations or until convergence\n",
    "    for iter in range(max_iter):\n",
    "        Q = np.zeros(n)  # Create a new array to store PageRank values for this iteration\n",
    "        sink_weight = 0\n",
    "\n",
    "        # Analyze number of sink nodes and calculate their weights\n",
    "        for j in range(n):\n",
    "            airport = airports_list[j]\n",
    "            \n",
    "            if airport.outweight == 0:\n",
    "                # Sink node: no outgoing flights, accumulate its PageRank\n",
    "                sink_weight += airport.pageIndex\n",
    "\n",
    "        # Calculate new PageRank for each airport\n",
    "        for j in range(n):\n",
    "            airport = airports_list[j]\n",
    "            link_sum = 0\n",
    "\n",
    "            if airport.outweight != 0:\n",
    "                # For airports with outgoing flights, accumulate weighted contributions from all outbound airports\n",
    "                for code, weight in airport.routeHash.items():\n",
    "                    linked_airport = airport_hash[code]\n",
    "                    link_sum += ((linked_airport.pageIndex * weight) / airport.outweight) + (sink_weight / n)\n",
    "            else:\n",
    "                # For sink nodes, distribute its PageRank equally among all airports\n",
    "                link_sum += sink_weight / n\n",
    "\n",
    "            # Calculate the new PageRank for airport `j`\n",
    "            Q[j] = L * link_sum + teleport\n",
    "\n",
    "            # Push (page rank, airport code) to the heap with negative rank for max-heap behavior\n",
    "            heappush(heap, (-Q[j], airport.code))\n",
    "\n",
    "        # Check for convergence based on L1 norm (difference between new and old PageRank)\n",
    "        if np.linalg.norm(Q - P, 1) < epsilon:\n",
    "            time2 = time.time()\n",
    "            print(f\"Converged after {iter + 1} iterations and {round(time2 - time1, 3)} s\")\n",
    "            # After convergence, return the sorted heap\n",
    "            return heap\n",
    "\n",
    "        # Update PageRank vector for the next iteration\n",
    "        P = Q\n",
    "    \n",
    "    time2 = time.time()\n",
    "    print(f\"Reached max iterations: {max_iter}. Time {round(time2 - time1, 3)} s\")\n",
    "    return heap\n",
    "\n",
    "def outputPageRanks(sorted_list, output_filename):\n",
    "    with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "        for rank, airport in sorted_list:\n",
    "            file.write(f\"{-rank:.10f}\\t{airport}\\n\")\n",
    "\n",
    "#### Execute in main ####\n",
    "readAirports(\"airports_test.txt\")\n",
    "readRoutes(\"routes_test.txt\")\n",
    "\n",
    "\n",
    "# Update weights for each airport so that they are constant\n",
    "time1 = time.time()\n",
    "for airport in airportList:\n",
    "    airport.pageIndex = 1/len(airportList)\n",
    "\n",
    "sorted_weights = computePageRanks(airportList, airportHash)\n",
    "\n",
    "outputPageRanks(sorted_weights, output_filename = \"sorted_weights.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check weights sum 1\n",
    "weights = [w[0] for w in sorted_weights]\n",
    "sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.5), np.float64(0.5)]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
